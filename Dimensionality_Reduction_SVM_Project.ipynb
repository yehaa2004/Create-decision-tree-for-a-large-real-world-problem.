{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d37c0678",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction using SVM\n",
    "### Mini Project for Machine Learning\n",
    "---\n",
    "**Objective:** Compare the performance of SVM classifier before and after applying dimensionality reduction techniques such as PCA and LDA.\n",
    "\n",
    "**Dataset:** `sklearn.datasets.load_digits`\n",
    "\n",
    "**Tools Used:** Python, scikit-learn, matplotlib, seaborn\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445db8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# PROJECT: Dimensionality Reduction using SVM\n",
    "\n",
    "# Uncomment if needed:\n",
    "# !pip install scikit-learn matplotlib numpy seaborn\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "digits = datasets.load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(X_train)\n",
    "X_test_std = scaler.transform(X_test)\n",
    "\n",
    "pca = PCA(n_components=20)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "print(f\"Explained variance ratio (PCA): {np.sum(pca.explained_variance_ratio_):.2f}\")\n",
    "\n",
    "svm_orig = SVC(kernel='rbf', gamma='scale')\n",
    "svm_orig.fit(X_train_std, y_train)\n",
    "y_pred_orig = svm_orig.predict(X_test_std)\n",
    "acc_orig = accuracy_score(y_test, y_pred_orig)\n",
    "print(f\"Accuracy (without PCA): {acc_orig:.4f}\")\n",
    "\n",
    "svm_pca = SVC(kernel='rbf', gamma='scale')\n",
    "svm_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = svm_pca.predict(X_test_pca)\n",
    "acc_pca = accuracy_score(y_test, y_pred_pca)\n",
    "print(f\"Accuracy (with PCA=20): {acc_pca:.4f}\")\n",
    "\n",
    "lda = LDA(n_components=9)\n",
    "X_train_lda = lda.fit_transform(X_train_std, y_train)\n",
    "X_test_lda = lda.transform(X_test_std)\n",
    "svm_lda = SVC(kernel='rbf', gamma='scale')\n",
    "svm_lda.fit(X_train_lda, y_train)\n",
    "y_pred_lda = svm_lda.predict(X_test_lda)\n",
    "acc_lda = accuracy_score(y_test, y_pred_lda)\n",
    "print(f\"Accuracy (with LDA): {acc_lda:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0095edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n--- Classification Reports ---\")\n",
    "print(\"Original Data:\\n\", classification_report(y_test, y_pred_orig))\n",
    "print(\"PCA Data:\\n\", classification_report(y_test, y_pred_pca))\n",
    "print(\"LDA Data:\\n\", classification_report(y_test, y_pred_lda))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630ec2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pca_2d = PCA(n_components=2)\n",
    "X_proj = pca_2d.fit_transform(X_train_std)\n",
    "plt.figure(figsize=(7,6))\n",
    "sns.scatterplot(x=X_proj[:,0], y=X_proj[:,1], hue=y_train, palette='tab10', s=20, alpha=0.7)\n",
    "plt.title(\"2D PCA Projection of Digits Data\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.legend([],[], frameon=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacdf6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cm = confusion_matrix(y_test, y_pred_pca)\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title(\"Confusion Matrix (SVM + PCA)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "383df964",
   "metadata": {},
   "source": [
    "## Summary\n",
    "- PCA reduced features from 64 to 20 with ~97% accuracy.\n",
    "- LDA used 9 components (for 10 classes) and gave ~96% accuracy.\n",
    "- Dimensionality reduction improves efficiency while maintaining accuracy.\n",
    "- This demonstrates how PCA/LDA can simplify datasets before applying SVMs.\n",
    "\n",
    "**Applications:** Image recognition, bioinformatics, text classification, and real-time systems where computation cost matters."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
